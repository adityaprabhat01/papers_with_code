{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (convE1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convE2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convE3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convE4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convE5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convE6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convE7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convE8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convE9): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convE10): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convT1): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (convD1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convD2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convT2): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (convD3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convD4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convT3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (convD5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convD6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convT4): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (convD7): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convD8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convD9): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #ENCODER\n",
    "        \n",
    "        self.convE1 = nn.Conv2d(1, 64, kernel_size = (3, 3), stride = 1, padding = 1)#512x512\n",
    "        self.convE2 = nn.Conv2d(64, 64, kernel_size = (3, 3), stride = 1, padding = 1)#512x512\n",
    "        self.convE3 = nn.Conv2d(64, 128, kernel_size = (3, 3), stride = 1, padding = 1)#256x256\n",
    "        self.convE4 = nn.Conv2d(128, 128, kernel_size = (3, 3), stride = 1, padding = 1)#256x256\n",
    "        self.convE5 = nn.Conv2d(128, 256, kernel_size = (3, 3), stride = 1, padding = 1)#128x128\n",
    "        self.convE6 = nn.Conv2d(256, 256, kernel_size = (3, 3), stride = 1, padding = 1)#128x128\n",
    "        self.convE7 = nn.Conv2d(256, 512, kernel_size = (3, 3), stride = 1, padding = 1)#64x64\n",
    "        self.convE8 = nn.Conv2d(512, 512, kernel_size = (3, 3), stride = 1, padding = 1)#64x64\n",
    "        self.convE9 = nn.Conv2d(512, 1024, kernel_size = (3, 3), stride = 1, padding = 1)#32x32\n",
    "        self.convE10 = nn.Conv2d(1024, 1024, kernel_size = (3, 3), stride = 1, padding = 1)#32x32\n",
    "        \n",
    "        #DECODER\n",
    "        \n",
    "        self.convT1 = nn.ConvTranspose2d(1024, 512, kernel_size = (4, 4), stride = 2, padding = 1)#64x64\n",
    "        #concat\n",
    "        self.convD1 = nn.Conv2d(1024, 512, kernel_size = (3, 3), stride = 1, padding = 1)#64x64\n",
    "        self.convD2 = nn.Conv2d(512, 512, kernel_size = (3, 3), stride = 1, padding = 1)#64x64\n",
    "        \n",
    "        self.convT2 = nn.ConvTranspose2d(512, 256, kernel_size = (4, 4), stride = 2, padding = 1)#128x128\n",
    "        #concat\n",
    "        self.convD3 = nn.Conv2d(512, 256, kernel_size = (3, 3), stride = 1, padding = 1)#128x128\n",
    "        self.convD4 = nn.Conv2d(256, 256, kernel_size = (3, 3), stride = 1, padding = 1)#128x128\n",
    "        \n",
    "        self.convT3 = nn.ConvTranspose2d(256, 128, kernel_size = (4, 4), stride = 2, padding = 1)#256x256\n",
    "        #concat\n",
    "        self.convD5 = nn.Conv2d(256, 128, kernel_size = (3, 3), stride = 1, padding = 1)#256x256\n",
    "        self.convD6 = nn.Conv2d(128, 128, kernel_size = (3, 3), stride = 1, padding = 1)#256x256\n",
    "        \n",
    "        self.convT4 = nn.ConvTranspose2d(128, 64, kernel_size = (4, 4), stride = 2, padding = 1)\n",
    "        #concat\n",
    "        self.convD7 = nn.Conv2d(128, 64, kernel_size = (3, 3), stride = 1, padding = 1)#512x512\n",
    "        self.convD8 = nn.Conv2d(64, 64, kernel_size = (3, 3), stride = 1, padding = 1)#512x512\n",
    "        self.convD9 = nn.Conv2d(64, 1, kernel_size = (3, 3), stride = 1, padding = 1)#512x512\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #ENCODER\n",
    "        \n",
    "        x1 = F.leaky_relu(self.convE1(x))\n",
    "        x1_concat = F.leaky_relu(self.convE2(x1))\n",
    "        \n",
    "        x2 = F.max_pool2d(x1_concat, kernel_size = (2, 2), stride = 2, padding = 0)#256x256\n",
    "        x2 = F.leaky_relu(self.convE3(x2))\n",
    "        x2_concat = F.leaky_relu(self.convE4(x2))\n",
    "        \n",
    "        x3 = F.max_pool2d(x2_concat, kernel_size = (2, 2), stride = 2, padding = 0)#128x128\n",
    "        x3 = F.leaky_relu(self.convE5(x3))\n",
    "        x3_concat = F.leaky_relu(self.convE6(x3))\n",
    "        \n",
    "        x4 = F.max_pool2d(x3_concat, kernel_size = (2, 2), stride = 2, padding = 0)#64x64\n",
    "        x4 = F.leaky_relu(self.convE7(x4))\n",
    "        x4_concat = F.leaky_relu(self.convE8(x4))\n",
    "        \n",
    "        x5 = F.max_pool2d(x4_concat, kernel_size = (2, 2), stride = 2, padding = 0)#32x32\n",
    "        x5 = F.leaky_relu(self.convE9(x5))\n",
    "        x5 = F.leaky_relu(self.convE10(x5))\n",
    "        \n",
    "        #DECODER\n",
    "        \n",
    "        x5 = self.convT1(x5)\n",
    "        x5 = torch.cat((x5, x4_concat), 1)\n",
    "        x5 = F.leaky_relu(self.convD1(x5))\n",
    "        x5 = F.leaky_relu(self.convD2(x5))\n",
    "        \n",
    "        x5 = self.convT2(x5)\n",
    "        x5 = torch.cat((x5, x3_concat), 1)\n",
    "        x5 = F.leaky_relu(self.convD3(x5))\n",
    "        x5 = F.leaky_relu(self.convD4(x5))\n",
    "        \n",
    "        x5 = self.convT3(x5)\n",
    "        x5 = torch.cat((x5, x2_concat), 1)\n",
    "        x5 = F.leaky_relu(self.convD5(x5))\n",
    "        x5 = F.leaky_relu(self.convD6(x5))\n",
    "        \n",
    "        x5 = self.convT4(x5)\n",
    "        x5 = torch.cat((x5, x1_concat), 1)\n",
    "        x5 = F.leaky_relu(self.convD7(x5))\n",
    "        x5 = F.leaky_relu(self.convD8(x5))\n",
    "        x5 = torch.sigmoid(self.convD9(x5))\n",
    "        \n",
    "        return x5\n",
    "\n",
    "unet = UNet()\n",
    "unet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
